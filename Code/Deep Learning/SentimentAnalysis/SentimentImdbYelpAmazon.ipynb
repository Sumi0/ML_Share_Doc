{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "SentimentImdbYelpAmazon.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysykyOagzgxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AqRnAUAzgxV",
        "colab_type": "text"
      },
      "source": [
        "# Read data from review files "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9osMMIPkzgxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviewDataPath = {'yelp': 'yelp_labelled.txt',\n",
        "                 'amazon': 'amazon_cells_labelled.txt',\n",
        "                 'imdb': 'imdb_labelled.txt'}\n",
        "reviewList = []\n",
        "\n",
        "for source, filepath in reviewDataPath.items():\n",
        "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
        "    # Add another column filled with the source name\n",
        "    df['source'] = source \n",
        "    reviewList.append(df)\n",
        "\n",
        "df = pd.concat(reviewList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0re3lyLLzgxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_imdb = df[df['source'] == 'amazon']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cai_0tDHzgxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "67ee3867-87a1-40dd-f696-516579d68d83"
      },
      "source": [
        "review_imdb.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   sentence  1000 non-null   object\n",
            " 1   label     1000 non-null   int64 \n",
            " 2   source    1000 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 31.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_pawS4Wzgxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6b717993-5f5a-4b5d-9779-a3b27e9823d9"
      },
      "source": [
        "# Just a look at data\n",
        "print(df.iloc[:10])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            sentence  label source\n",
            "0                           Wow... Loved this place.      1   yelp\n",
            "1                                 Crust is not good.      0   yelp\n",
            "2          Not tasty and the texture was just nasty.      0   yelp\n",
            "3  Stopped by during the late May bank holiday of...      1   yelp\n",
            "4  The selection on the menu was great and so wer...      1   yelp\n",
            "5     Now I am getting angry and I want my damn pho.      0   yelp\n",
            "6              Honeslty it didn't taste THAT fresh.)      0   yelp\n",
            "7  The potatoes were like rubber and you could te...      0   yelp\n",
            "8                          The fries were great too.      1   yelp\n",
            "9                                     A great touch.      1   yelp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKnAV5b-zgxi",
        "colab_type": "text"
      },
      "source": [
        "# Split data in train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA_ojg_czgxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LLGa32Jzgxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_yelp = df[df['source'] == 'yelp']\n",
        "\n",
        "sentences = review_yelp['sentence'].values\n",
        "\n",
        "y = review_yelp['label'].values\n",
        "\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
        "    sentences, y, test_size=0.25, random_state=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF-dIghezgxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83070126-d2f2-4e60-dc57-0c86ed56bf8e"
      },
      "source": [
        "sentences_train.size"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJLdXxSVzgxr",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z0TH-6rzgxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb30c6be-b1c5-4d0c-fc18-eb95e854c2bf"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtD2vPE0zgxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24yeZCjBzgxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding 1 because of reserved 0 index\n",
        "# The indexing is ordered after the most common words in the text, \n",
        "# which you can see by the word the having the index 1. \n",
        "# It is important to note that the index 0 is reserved \n",
        "# and is not assigned to any word. This zero index is used for padding,\n",
        "# because every statement is not of same size\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwIlhD-bzgx1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "399d9f60-7db0-4a99-9fa1-f67924d6f50e"
      },
      "source": [
        "print(vocab_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPDUP4XZzgx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb_NVj0Izgx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "440cced5-a33c-4d6c-95c8-1e628b6a72b2"
      },
      "source": [
        "print(sentences_train[1:6])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sorry, I will not be getting food from here anytime soon :('\n",
            " 'Of all the dishes, the salmon was the best, but all were great.'\n",
            " 'The fries were not hot, and neither was my burger.'\n",
            " \"In fact I'm going to round up to 4 stars, just because she was so awesome.\"\n",
            " 'Will go back next trip out.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgPj6m5Jzgx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "47b082c9-884b-4c4e-a0d7-97b325c018f1"
      },
      "source": [
        "print(X_train[1])\n",
        "print(X_train[2])\n",
        "print(X_train[3])\n",
        "print(X_train[4])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[740, 4, 46, 12, 20, 160, 10, 72, 35, 355, 232]\n",
            "[11, 43, 1, 171, 1, 283, 3, 1, 47, 26, 43, 24, 22]\n",
            "[1, 233, 24, 12, 209, 2, 741, 3, 23, 125]\n",
            "[14, 356, 83, 126, 5, 742, 59, 5, 357, 96, 41, 127, 234, 3, 25, 161]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1qaR5DxzgyA",
        "colab_type": "raw"
      },
      "source": [
        "With Tokenizer, the resulting vectors equal the length of each text, and the numbers don’t denote counts,\n",
        "but rather correspond to the word values from the dictionary tokenizer.word_index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXZ_I_Q6zgyA",
        "colab_type": "text"
      },
      "source": [
        "# PAD Sequance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cYGz7YAzgyB",
        "colab_type": "raw"
      },
      "source": [
        "Each text sequence has in most cases different length of words. \n",
        "To counter this, pad_sequence() is used ,which simply pads the sequence of words with zeros. \n",
        "By default, it prepends zeros but we want to append them.\n",
        "Typically it does not matter whether you prepend or append zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWpfBceUzgyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeA4417vzgyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# maxlen parameter to specify how long the sequences should be. \n",
        "#This cuts sequences that exceed that number.\n",
        "\n",
        "maxlen = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaDFD49hzgyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h6l2_JuzgyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8ce39dd5-4de2-4c1f-a5e3-15ad9dd5a0ed"
      },
      "source": [
        "print(X_train[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[740   4  46  12  20 160  10  72  35 355 232   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boTXc6SYzgyM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2de5688e-0161-40dc-e161-2b117094e6b0"
      },
      "source": [
        "print(X_train[4])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 14 356  83 126   5 742  59   5 357  96  41 127 234   3  25 161   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZYEDB3azgyO",
        "colab_type": "text"
      },
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8p2UZn1zgyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.models import Sequential\n",
        "#from keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "m = tf.keras.models\n",
        "layers = tf.keras.layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9mCFDHozgyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = m.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM5njqBIzgyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f56f1cc7-c279-41e6-b26f-d2d024fe4604"
      },
      "source": [
        "# vocab size is 1750 \n",
        "# input_length is size of review text after tokenization and pad sequance\n",
        "embedding_dim = 80\n",
        "\n",
        "model.add(layers.Embedding(input_dim=vocab_size,\n",
        "                           output_dim=embedding_dim,\n",
        "                           input_length=maxlen))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 100, 80)           139760    \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 8000)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                80010     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 219,781\n",
            "Trainable params: 219,781\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIEo4fMczgyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBzCjyekzgyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "da3ee5cd-8ee1-4d21-c241-8acf2d93922a"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=18,verbose=True,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)\n",
        "\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/18\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.6959 - accuracy: 0.5013 - val_loss: 0.6906 - val_accuracy: 0.5200\n",
            "Epoch 2/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.6053 - val_loss: 0.6973 - val_accuracy: 0.4840\n",
            "Epoch 3/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.8453 - val_loss: 0.5964 - val_accuracy: 0.6640\n",
            "Epoch 4/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.2524 - accuracy: 0.9547 - val_loss: 0.5613 - val_accuracy: 0.7200\n",
            "Epoch 5/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9853 - val_loss: 0.5347 - val_accuracy: 0.7320\n",
            "Epoch 6/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9960 - val_loss: 0.5490 - val_accuracy: 0.7600\n",
            "Epoch 7/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9973 - val_loss: 0.6029 - val_accuracy: 0.7320\n",
            "Epoch 8/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9987 - val_loss: 0.5663 - val_accuracy: 0.7480\n",
            "Epoch 9/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.7600\n",
            "Epoch 10/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5995 - val_accuracy: 0.7400\n",
            "Epoch 11/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.7640\n",
            "Epoch 12/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.7640\n",
            "Epoch 13/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6451 - val_accuracy: 0.7560\n",
            "Epoch 14/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.7720\n",
            "Epoch 15/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6587 - val_accuracy: 0.7720\n",
            "Epoch 16/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6763 - val_accuracy: 0.7600\n",
            "Epoch 17/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6809 - val_accuracy: 0.7600\n",
            "Epoch 18/18\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.7800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnlgfi98zgyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fc4ab0a-39d7-48a1-836b-fafbfa590d6b"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1V6dEROzgyg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51de3c61-92cd-43ae-be44-32b12dc77831"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.7800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0j18cGDzgyj",
        "colab_type": "text"
      },
      "source": [
        "# Let's do the prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MduBTutzgyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3382d44e-3038-4c5a-9378-642595982734"
      },
      "source": [
        "import numpy as np\n",
        "phrase = \"food was stale\"\n",
        "#phrase = \"bad service\"\n",
        "\n",
        "# Use same as tokenzier object which was used for training data\n",
        "tokens = tokenizer.texts_to_sequences([phrase])\n",
        "\n",
        "# same as for training\n",
        "pad_tokens = pad_sequences(tokens, padding='post', maxlen=maxlen)\n",
        "\n",
        "print(tokens)\n",
        "print(pad_tokens)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10, 3, 611]]\n",
            "[[ 10   3 611   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkF-891Yzgyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val = model.predict_classes(pad_tokens)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFK-7nPeHn-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57dbb1db-c9d0-47e9-9c95-67fb8d7e6a6e"
      },
      "source": [
        "print(val[0][0])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fXXDcG8zgyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictSentiments ( indexvalue):\n",
        "    \n",
        "    reviewSentiment = ''\n",
        "    \n",
        "    if (val[0][0] == 0):\n",
        "        reviewSentiment = 'Customer is gone forever,'\n",
        "    else:\n",
        "        reviewSentiment = 'you got back your customer'\n",
        "\n",
        "    return reviewSentiment;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uZterRBzgyu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9adeda0b-203c-4d01-c95f-24bcffcb0c83"
      },
      "source": [
        "print(predictSentiments(val[0][0]))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you got back your customer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5kqH-Jizgyx",
        "colab_type": "text"
      },
      "source": [
        "# Save the model to re-use later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0QGouqszgyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pickle\n",
        "\n",
        "# Creates a HDF5 file 'my_model.h5'\n",
        "model.save('my_model.h5')\n",
        "\n",
        "# Deletes the existing model\n",
        "#del model  \n",
        "\n",
        "\n",
        "# saving tokenizer \n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZScinmLQzgyz",
        "colab_type": "text"
      },
      "source": [
        "# Load Model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyfI5SNVzgy0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6b2026b-e96b-4b6d-8b10-706cde547bfe"
      },
      "source": [
        "# loading\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer_saved = pickle.load(handle)\n",
        "\n",
        "# Returns a compiled model identical to the previous one\n",
        "model_saved = m.load_model('my_model.h5')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grmADOsPzgy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "38c97e98-16d8-43f5-9b07-9cd3ec2238ee"
      },
      "source": [
        "#review_sen = \"good food ,will come again\"\n",
        "review_sen = \"bad service\"\n",
        "\n",
        "tokens_sen = tokenizer_saved.texts_to_sequences([review_sen])\n",
        "pad_tokens_sen = pad_sequences(tokens_sen, padding='post', maxlen=maxlen)\n",
        "\n",
        "print(tokens_sen)\n",
        "print(pad_tokens_sen)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[90, 19]]\n",
            "[[90 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5WyxSQVzgy5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7ce2c97-a9a6-49d3-bd8b-258d13d97073"
      },
      "source": [
        "val = model_saved.predict_classes(pad_tokens_sen)\n",
        "print(predictSentiments(val[0][0]))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Customer is gone forever,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzlo2zzuzgy7",
        "colab_type": "text"
      },
      "source": [
        "# Another model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyc-8Swczgy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(layers.Embedding(input_dim=vocab_size,output_dim=embedding_dim,input_length=maxlen))\n",
        "\n",
        "model2.add(layers.GlobalMaxPool1D())\n",
        "\n",
        "model2.add(layers.Dense(10, activation='relu'))\n",
        "model2.add(layers.Dense(1, activation='sigmoid'))\n",
        "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBsA0t_ezgy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history2 = model2.fit(X_train, y_train,\n",
        "                    epochs=20,verbose=True,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIHFlAYHzgzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model2.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTkMeScazgzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model2.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy: {:.4f}\".format(accuracy))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81T1n1XizgzH",
        "colab_type": "text"
      },
      "source": [
        "# Using Pre-Trained GloVe vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxfoJ2KBzgzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "    \n",
        "    vocab_size = len(word_index) + 1 \n",
        "    # Adding again 1 because of reserved 0 index\n",
        "    \n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as file:\n",
        "        for line in file:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word]\n",
        "                print(\"{} {} \".format(word,idx))\n",
        "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luD-H1yIzgzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 50\n",
        "\n",
        "filePath = 'GloVe_PreTrained/glove.6B.50d.txt'\n",
        "\n",
        "embedding_matrix = create_embedding_matrix(filePath,\n",
        "                                           tokenizer.word_index, \n",
        "                                           embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq920uHozgzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(embedding_matrix[0:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR7kyPO-zgzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "model3.add(layers.Embedding(vocab_size, \n",
        "                            embedding_dim,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=maxlen,\n",
        "                            trainable=True)) # Make it False\n",
        "#model3.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model3.add(layers.GlobalMaxPool1D())\n",
        "\n",
        "model3.add(layers.Dense(10, activation='relu'))\n",
        "model3.add(layers.Dense(1, activation='sigmoid'))\n",
        "model3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz4Eb9nNzgzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history3 = model3.fit(X_train, y_train,\n",
        "                    epochs=20,verbose=True,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2klSZHpwzgzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model3.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89mzIEKfzgzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model3.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag18jADGzgza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKkyUNmBzgzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}